"""
Exemplo de Uso do Sistema de Detec√ß√£o de Exoplanetas
Demonstra todas as funcionalidades principais do sistema
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from exoplanet_ml import ExoplanetDetector
from data_visualizer import ExoplanetVisualizer
from transit_analyzer import TransitAnalyzer
import json

def demonstrate_ml_classification():
    """Demonstra classifica√ß√£o ML de exoplanetas"""
    
    print("ü§ñ DEMONSTRA√á√ÉO: Classifica√ß√£o ML de Exoplanetas")
    print("=" * 60)
    
    # Inicializar detector
    detector = ExoplanetDetector()
    
    # Carregar e processar dados
    print("üìä Carregando dados de exemplo...")
    df = detector.prepare_sample_data()
    print(f"   Dataset: {len(df)} objetos")
    
    processed_df, features = detector.preprocess_data(df)
    print(f"   Caracter√≠sticas analisadas: {len(features)}")
    
    # Treinar modelos
    print("\nüöÄ Treinando modelos ML...")
    results, X_test, y_test = detector.train_models(processed_df, features)
    
    print(f"\nüìà RESULTADOS DO TREINAMENTO:")
    for model_name, metrics in results.items():
        print(f"  {model_name}:")
        print(f"    ‚Ä¢ Acur√°cia: {metrics['accuracy']:.1%}")
        print(f"    ‚Ä¢ CV Score: {metrics['cross_val_mean']:.1%} ¬± {metrics['cross_val_std']:.1%}")
    
    # Predi√ß√µes de exemplo
    print(f"\nüîÆ EXEMPLOS DE PREDI√á√ïES:")
    
    # Selecionar alguns casos interessantes
    interesting_cases = []
    
    # Caso 1: Potencial planeta habit√°vel (per√≠odo longo, tamanho similar √† Terra)
    case1_idx = processed_df[
        (processed_df['koi_prad'] > 0.8) & (processed_df['koi_prad'] < 1.2) &
        (processed_df['koi_period'] > 200) & (processed_df['koi_period'] < 400)
    ].index[0] if len(processed_df) > 0 else 0
    
    # Caso 2: Hot Jupiter (per√≠odos curtos)
    case2_idx = processed_df[
        (processed_df['koi_period'] < 10) & (processed_df['koi_prad'] > 10)
    ].index[0] if len(processed_df) > 0 else 1
    
    cases = [
        (case1_idx, "Potencial Planeta Habit√°vel"),
        (case2_idx, "Hot Jupiter Candidate")
    ]
    
    for idx, description in cases:
        if idx < len(processed_df):
            data_point = processed_df[features].iloc[idx]
            true_label = processed_df['target'].iloc[idx]
            
            # Buscar palavra descritiva original
            true_class_name = detector.label_encoder.inverse_transform([true_label])[0]
            
            # Fazer predi√ß√£o
            prediction = detector.predict_exoplanet(data_point.values)
            
            print(f"\n  {description}:")
            print(f"    Per√≠odo: {data_point['koi_period']:.1f} dias")
            print(f"    Raio: {data_point['koi_prad']:.1f} Raio Terra")
            print(f"    Temperatura: {data_point['koi_teq']:.0f} K")
            print(f"    Classifica√ß√£o Real: {true_class_name}")
            print(f"    IA Analisa Como: {prediction['ensemble_prediction']}")
            
            # Mostra probabilidades detalhadas
            for model_name, probs in prediction['probabilities'].items():
                print(f"    {model_name}:")
                for class_name, prob in probs.items():
                    print(f"      {class_name}: {prob:.1%}")
    
    return detector, results

def demonstrate_data_visualization():
    """Demonstra visualiza√ß√£o de dados"""
    
    print("\n\nüìä DEMONSTRA√á√ÉO: Visualiza√ß√£o de Dados Astron√¥micos")
    print("=" * 60)
    
    visualizer = ExoplanetVisualizer()
    
    # Carregar dados
    print("üî≠ Gerando dados astron√¥micos sint√©ticos...")
    data = visualizer.load_nasa_datasets_sample()
    
    # Gerar relat√≥rio de an√°lise
    print("üìã Gerando relat√≥rio de an√°lise explorat√≥ria...")
    report = visualizer.generate_analysis_report(data)


    print("\nüìà ESTAT√çSTICAS GERAIS:")
    print(f"  Total de objetos: {report['total_objects']:,}")
    print(f"  Caracter√≠sticas analisadas: {report['features_count']}")
    print(f"  Dados faltantes: {report['missing_data']}")
    print(f"  Balanceamento de classes: {report['class_balance']:.2f}")
    
    print(f"\nüéØ DISTRIBUI√á√ÉO POR CLASSE:")
    for class_name, count in report['class_distribution'].items():
        percentage = count / report['total_objects'] * 100
        print(f"  {class_name}: {count:,} ({percentage:.1f}%)")
    
    print(f"\nüîó CORRELA√á√ïES IMPORTANTES:")
    print("  (Com per√≠odo orbital - baseado em dados astron√¥micos)")
    for feature, correlation in report['strong_correlations'].items():
        print(f"  {feature}: {correlation:.3f}")
    
    print(f"\n‚ö†Ô∏è  OUTLIERS DETECTADOS:")
    print(f"  Per√≠odos orbitais: {report['outliers_period']}")
    print(f"  Raios planet√°rios: {report['outliers_radius']}")
    
    print("\nüí° INSIGHTS ASTRON√îMICOS:")
    print("  ‚Ä¢ Per√≠odos orbitais seguem distribui√ß√£o log-normal")
    print("  ‚Ä¢ Planetas terrestres concentrados em 0.8-1.5 raios terrestres")
    print("  ‚Ä¢ Temperaturas de equil√≠brio correlacionadas com insola√ß√£o")
    print("  ‚Ä¢ Distribui√ß√£o de massa estelar afeta detectabilidade")
    
    return visualizer, data

def demonstrate_transit_analysis():
    """Demonstra an√°lise de tr√¢nsitos"""
    
    print("\n\n‚è∞ DEMONSTRA√á√ÉO: An√°lise de Tr√¢nsitos Planet√°rios")
    print("=" * 60)
    
    analyzer = TransitAnalyzer()
    
    print("üåü Simulando diferentes cen√°rios planet√°rios...")
    
    # Cen√°rios planet√°rios interessantes
    scenarios = [
        {
            'name': 'üåç Terra-Like',
            'per√≠odo_real': 365.25,
            'dura√ß√£o_real': 13.0,
            'profundidade_real': 0.01,
            'descri√ß√£o': '√ìrbita anual, tr√¢nsito ~13h, redu√ß√£o de 0.01%'
        },
        {
            'name': 'üî• Hot Jupiter',
            'per√≠odo_real': 3.0,
            'dura√ß√£o_real': 2.5,
            'profundidade_real': 1.0,
            'descri√ß√£o': '√ìrbita r√°pida 3 dias, tr√¢nsito ~2.5h, redu√ß√£o de 1%'
        },
        {
            'name': 'üåô Super-Lua',
            'per√≠odo_real': 28.0,
            'dura√ß√£o_real': 8.0,
            'profundidade_real': 0.05,
            'descri√ß√£o': 'Planeta pequeno, √≥rbita de 28 dias, detect√°vel'
        }
    ]
    
    results = []
    
    for scenario in scenarios:
        print(f"\nüìã Analisando {scenario['name']}:")
        print(f"   {scenario['descri√ß√£o']}")
        
        # Simular curva de luz
        light_curve = analyzer.generate_synthetic_transit(
            period_days=scenario['per√≠odo_real'],
            duration_hours=scenario['dura√ß√£o_real'],
            depth_percent=scenario['profundidade_real'],
            noise_level=0.001
        )
        
        # Detectar tr√¢nsito
        detection = analyzer.detect_transits(light_curve)
        
        # Analisar formato
        shape_analysis = analyzer.analyze_transit_shape(light_curve)
        
        # Calcular precis√£o
        period_error = abs(scenario['per√≠odo_real'] - detection['detected_period_days'])
        period_error_percent = period_error / scenario['per√≠odo_real'] * 100
        
        depth_error = abs(scenario['profundidade_real'] - detection['estimated_depth_percent'])
        depth_error_percent = depth_error / scenario['profundidade_real'] * 100
        
        result = {
            'cenario': scenario['name'],
            'periodo_real': scenario['per√≠odo_real'],
            'periodo_detectado': detection['detected_period_days'],
            'periodo_erro': period_error_percent,
            'profundidade_real': scenario['profundidade_real'],
            'profundidade_detectada': detection['estimated_depth_percent'],
            'profundidade_erro': depth_error_percent,
            'confianca': detection['confidence'],
            'dura√ß√£o_detectada': shape_analysis['transit_duration_hours'] if shape_analysis else 0
        }
        
        results.append(result)
        
        print(f"   ‚úÖ Per√≠odo detectado: {detection['detected_period_days']:.1f} dias (erro: {period_error_percent:.1f}%)")
        print(f"   üìâ Profundidade detectada: {detection['estimated_depth_percent']:.4f}% (erro: {depth_error_percent:.1f}%)")
        print(f"   ‚è±Ô∏è  Dura√ß√£o detectada: {shape_analysis['transit_duration_hours']:.1f}h" if shape_analysis else "   ‚è±Ô∏è  Dura√ß√£o n√£o detectada")
        print(f"   üéØ Confian√ßa: {detection['confidence']:.1f}")
    
    # Resumo comparativo
    print(f"\nüìä RESUMO COMPARATIVO:")
    print(f"{'Cen√°rio':<15} {'Per√≠odo Erro':<12} {'Profund. Erro':<12} {'Confian√ßa':<10}")
    print("-" * 50)
    
    for result in results:
        print(f"{result['cenario']:<15} {result['periodo_erro']:<12.1f}% {result['profundidade_erro']:<12.1f}% {result['confianca']:<10.1f}")
    
    return analyzer, results

def generate_synthetic_research_dataset():
    """Gera dataset sint√©tico para pesquisa"""
    
    print("\n\nüî¨ GERANDO DATASET SINT√â√©tico PARA PESQUISA")
    print("=" * 60)
    
    # Usar o detector para gerar dados pesquis√°veis
    detector = ExoplanetDetector()
    
    print("üìä Gerando dataset expandido (5,000 objetos)...")
    
    # Expandir dataset base
    base_data = detector.prepare_sample_data()
    
    # Replicar e modificar dados para criar consist√™ncia e padr√µes
    expanded_data = []
    
    planet_types = [
        {'name': 'Rocky Planets', 'radius_range': (0.5, 1.5), 'period_range': (50, 400), 'weight': 0.4},
        {'name': 'Gas Giants', 'radius_range': (8, 12), 'period_range': (300, 2000), 'weight': 0.3},
        {'name': 'Hot Jupiters', 'radius_range': (8, 12), 'period_range': (1, 10), 'weight': 0.2},
        {'name': 'Mini Neptunes', 'radius_range': (2, 4), 'period_range': (20, 150), 'weight': 0.1}
    ]
    
    samples_per_type = [int(5000 * pt['weight']) for pt in planet_types]
    
    for planet_type, n_samples in zip(planet_types, samples_per_type):
        print(f"  üåç Gerando {n_samples} {planet_type['name']}...")
        
        for _ in range(n_samples):
            sample = base_data.iloc[np.random.randint(0, len(base_data))].copy()
            
            # Modificar caracter√≠sticas baseadas no tipo planet√°rio
            sample['koi_prad'] = np.random.uniform(*planet_type['radius_range'])
            sample['koi_period'] = np.random.uniform(*planet_type['period_range'])
            
            # Correla√ß√µes realistas
            sample['koi_depth'] = (sample['koi_prad'] ** 2) * np.random.uniform(0.0005, 0.001)
            sample['koi_teq'] = 278 * (sample['koi_period']) ** (-0.4) * np.random.uniform(0.8, 1.2)
            
            # Modificar disposi√ß√£o baseada em caracter√≠sticas
            radius = sample['koi_prad']
            if 0.8 <= radius <= 1.2 and 100 <= sample['koi_period'] <= 400:
                sample['koi_disposition'] = 'CONFIRMED'
            elif radius > 8 and sample['koi_period'] < 20:
                sample['koi_disposition'] = 'CONFIRMED'
            else:
                sample['koi_disposition'] = np.random.choice(
                    ['CANDIDATE', 'FALSE POSITIVE'], 
                    p=[0.7, 0.3]
                )
            
            expanded_data.append(sample)
    
    final_dataset = pd.DataFrame(expanded_data)
    
    # Estat√≠sticas finais
    print(f"\n‚úÖ Dataset pesquis√°vel gerado:")
    print(f"   Total de objetos: {len(final_dataset):,}")
    
    disposition_counts = final_dataset['koi_disposition'].value_counts()
    print(f"   Distribui√ß√£o por classe:")
    for disp, count in disposition_counts.items():
        print(f"     {disp}: {count:,} ({count/len(final_dataset)*100:.1f}%)")
    
    # Salvar dataset
    output_file = 'data/synthetic_research_dataset.csv'
    final_dataset.to_csv(output_file, index=False)
    print(f"   üíæ Salvo em: {output_file}")
    
    return final_dataset

def demonstrate_full_workflow():
    """Demonstra workflow completo do sistema"""
    
    print("\n\nüöÄ WORKFLOW COMPLETO DO SISTEMA")
    print("=" * 60)
    
    print("1Ô∏è‚É£ Carregando dataset pesquis√°vel...")
    research_data = generate_synthetic_research_dataset()
    
    print("\n2Ô∏è‚É£ Treinando modelos com dataset expandido...")
    detector = ExoplanetDetector()
    processed_data, features = detector.preprocess_data(research_data)
    results, _, _ = detector.train_models(processed_data, features)
    
    print(f"\n3Ô∏è‚É£ MODELOS OTIMIZADOS:")
    best_model = max(results.items(), key=lambda x: x[1]['accuracy'])
    print(f"   üèÜ Melhor modelo: {best_model[0]} ({best_model[1]['accuracy']:.1%})")
    
    print("\n4Ô∏è‚É£ Analisando import√¢ncia das caracter√≠sticas...")
    feature_importance = detector.feature_importance
    if feature_importance:
        best_features = sorted(
            zip(features, feature_importance[best_model[0]]), 
            key=lambda x: x[1], 
            reverse=True
        )[:5]
        
        print("   üéØ Top 5 caracter√≠sticas:")
        for feature, importance in best_features:
            print(f"     {feature}: {importance:.3f}")
    
    print("\n5Ô∏è‚É£ Simulando an√°lise de novo objeto...")
    
    # Simular an√°lise de objeto potencialmente interessante
    simulation_data = {
        'koi_period': 365.25,    # √ìrbita terrestre
        'koi_prad': 1.05,        # Ligeiramente menor que Terra
        'koi_teq': 288,          # Temperatura adequada
        'koi_insol': 1.0,        # Insola√ß√£o terrestre
        'koi_depth': 0.0001,    # Profundidade detect√°vel
        'koi_duration': 13.0,    # Dura√ß√£o do tr√¢nsito
        'koi_impact': 0.5,       # √Çngulo moderado
        'koi_steff': 5778,       # Temperatura solar
        'koi_smass': 1.0,        # Massa solar
        'koi_srad': 1.0,         # Raio solar
        'koi_kepmag': 12.5       # Magnitude moderada
    }
    
    prediction = detector.predict_exoplanet(list(simulation_data.values()))
    
    print(f"       Objeto simulado:")
    print(f"       Per√≠odo: {simulation_data['koi_period']} dias")
    print(f"       Raio: {simulation_data['koi_prad']} Raio Terra")
    print(f"       Temperatura: {simulation_data['koi_teq']} K")
    print(f"\n   ü§ñ Predi√ß√£o IA: {prediction['ensemble_prediction']}")
    print(f"   üéØ Probabilidades:")
    
    for model_name, probs in prediction['probabilities'].items():
        best_class = max(probs.items(), key=lambda x: x[1])
        print(f"     {model_name}: {best_class[0]} ({best_class[1]:.1%})")
    
    print(f"\n‚ú® SISTEMA PRONTO PARA PESQUISA CIENT√çFICA!")
    print(f"   üìä Dataset: {len(research_data):,} objetos")
    print(f"   ü§ñ Modelos: {len(results)} treinados")
    print(f"   üéØ Melhor Acur√°cia: {best_model[1]['accuracy']:.1%}")
    
    return detector, research_data, results

def main():
    """Fun√ß√£o principal de demonstra√ß√£o"""
    
    print("DEMONSTRACAO COMPLETA DO SISTEMA DE DETECCAO DE EXOPLANETAS")
    print("NASA Missions Data Analysis with AI/ML")
    print("=" * 80)
    
    try:
        # Demonstra√ß√£o das capacidades principais
        detector, ml_results = demonstrate_ml_classification()
        
        visualizer, viz_data = demonstrate_data_visualization()
        
        analyzer, transit_results = demonstrate_transit_analysis()
        
        # Workflow completo
        final_detector, research_data, final_results = demonstrate_full_workflow()
        
        print("\n\nüéâ TODAS AS DEMONSTRA√á√ïES CONCLU√çDAS COM SUCESSO!")
        print("üöÄ O sistema est√° pronto para:")
        print("   üåê Interface Web Interativa")
        print("   üî¨ Pesquisa cient√≠fica avan√ßada")
        print("   üìä An√°lise de dados NASA")
        print("   üéØ Classifica√ß√£o automatizada")
        print("   ‚ö° Processamento em tempo real")
        
        print(f"\nüìã Para iniciar a interface web, execute:")
        print(f"   python run_system.py")
        print(f"   ou")
        print(f"   streamlit run streamlit_app.py")
        
    except Exception as e:
        print(f"‚ùå Erro durante demonstra√ß√£o: {str(e)}")
        print("üîß Execute 'python run_system.py' para diagn√≥stico completo")

if __name__ == "__main__":
    main()
